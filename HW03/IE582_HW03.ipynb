{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4157aef9-dc9c-473f-9de1-8f93c1828ae3",
   "metadata": {},
   "source": [
    "# IE 582 Homework 03 - Dorukhan Kılınç 2017402093"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6ce94fe8-3882-4f09-a2c4-bd75b4f89bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.metrics import accuracy_score\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb48fae4-4109-4103-a775-be8474cbd974",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read train data\n",
    "file_names = [\"uWaveGestureLibrary_X_TRAIN\",\n",
    "              \"uWaveGestureLibrary_Y_TRAIN\",\n",
    "              \"uWaveGestureLibrary_Z_TRAIN\"]\n",
    "\n",
    "data_train = [[], [], []]\n",
    "\n",
    "for i in range(3):\n",
    "    for line in open(file_names[i]):\n",
    "        data_train[i].append(line.split())\n",
    "    data_train[i] = np.array(data_train[i])\n",
    "    \n",
    "data_acc_train = np.ndarray(shape = (896, 316, 3), dtype = \"float\")\n",
    "\n",
    "for i in range(3):\n",
    "    data_acc_train[:,:, i] = data_train[i]\n",
    "\n",
    "data_v_train = np.zeros(shape = (896, 316, 3))\n",
    "\n",
    "data_v_train[:,0,:] = data_acc_train[:,0,:]\n",
    "\n",
    "for instance in range(896):\n",
    "    for time in range(2, 316):                   \n",
    "        data_v_train[instance, time, :] = data_v_train[instance, time - 1,:] + data_acc_train[instance, time - 1,:]\n",
    "        \n",
    "data_dist_train = np.zeros(shape = (896, 316, 3))\n",
    "data_dist_train[:,0,:] = data_acc_train[:,0,:]\n",
    "\n",
    "for instance in range(896):\n",
    "    for time in range(2, 316):                   \n",
    "        data_dist_train[instance, time, :] = data_dist_train[instance, time - 1,:] + data_v_train[instance, time - 1,:] + data_acc_train[instance, time - 1,:]/2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5a58e9c-b207-4865-959f-b71f70821c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read test data\n",
    "\n",
    "file_names2 = [\"uWaveGestureLibrary_X_TEST\",\n",
    "              \"uWaveGestureLibrary_Y_TEST\",\n",
    "              \"uWaveGestureLibrary_Z_TEST\"]\n",
    "\n",
    "data_test = [[], [], []]\n",
    "\n",
    "for i in range(3):\n",
    "    for line in open(file_names2[i]):\n",
    "        data_test[i].append(line.split())\n",
    "    data_test[i] = np.array(data_test[i])\n",
    "    \n",
    "data_acc_test = np.ndarray(shape = (3582, 316, 3), dtype = \"float\")\n",
    "\n",
    "for i in range(3):\n",
    "    data_acc_test[:,:, i] = data_test[i]\n",
    "\n",
    "data_v_test = np.zeros(shape = (3582, 316, 3))\n",
    "\n",
    "data_v_test[:,0,:] = data_acc_test[:,0,:]\n",
    "\n",
    "for instance in range(3582):\n",
    "    for time in range(2, 316):                   \n",
    "        data_v_test[instance, time, :] = data_v_test[instance, time - 1,:] + data_acc_test[instance, time - 1,:]\n",
    "        \n",
    "data_dist_test = np.zeros(shape = (3582, 316, 3))\n",
    "data_dist_test[:,0,:] = data_acc_test[:,0,:]\n",
    "\n",
    "for instance in range(3582):\n",
    "    for time in range(2, 316):                   \n",
    "        data_dist_test[instance, time, :] = data_dist_test[instance, time - 1,:] + data_v_test[instance, time - 1,:] + data_acc_test[instance, time - 1,:]/2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d759fb-671c-4d37-820e-516eccdf2929",
   "metadata": {},
   "source": [
    "## Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23e4e29-9b8f-4bf9-974d-9f17270c22c0",
   "metadata": {},
   "source": [
    "### Part a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7f398096-ffaf-4fe9-8320-4668df3ac4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare the concatanated distances\n",
    "data_dist_test_x = data_dist_test[:,1:,0]\n",
    "data_dist_test_y = data_dist_test[:,1:,1]\n",
    "data_dist_test_z = data_dist_test[:,1:,2]\n",
    "\n",
    "data_dist_test_concatenated = []\n",
    "\n",
    "for instance in range(3582):\n",
    "    data_dist_test_concatenated.append(np.concatenate((data_dist_test_x[instance,:],\n",
    "                                           data_dist_test_y[instance,:],\n",
    "                                           data_dist_test_z[instance,:])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "989869c0-43bd-414d-8980-aa50194da2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply PCA to the concatanated series\n",
    "#pca_concatanated = PCA(n_components=2)\n",
    "#X = np.array(pca_concatanated.fit_transform(data_dist_test_concatenated))\n",
    "X = np.array(data_dist_test_concatenated)\n",
    "\n",
    "y = data_dist_test[:,0,0]\n",
    "\n",
    "#k_values = np.arange(1, int(np.sqrt(3582)))\n",
    "k_values = np.arange(2, 11)\n",
    "\n",
    "\n",
    "cv_results_p1 = []\n",
    "cv_results_p2 = []\n",
    "\n",
    "\n",
    "for k in k_values:\n",
    "    \n",
    "    classifier1 = KNeighborsClassifier(n_neighbors=k, p = 1)\n",
    "    cv1 = cross_validate(classifier1, X, y, cv=10)\n",
    "    \n",
    "    classifier2 = KNeighborsClassifier(n_neighbors=k, p = 2)\n",
    "    cv2 = cross_validate(classifier2, X, y, cv=10)\n",
    "    \n",
    "    cv_results_p1.append(cv1)\n",
    "    cv_results_p2.append(cv2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0a6f41d9-6309-4071-b284-3b64e52d2fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "cv_means_p1 = np.zeros(len(k_values))\n",
    "cv_stds_p1 = np.zeros(len(k_values))\n",
    "\n",
    "cv_means_p2 = np.zeros(len(k_values))\n",
    "cv_stds_p2 = np.zeros(len(k_values))\n",
    "\n",
    "\n",
    "for i in range(len(k_values)):\n",
    "    \n",
    "    cv_means_p1[i] = np.mean(cv_results_p1[i][\"test_score\"])\n",
    "    cv_stds_p1[i] = np.std(cv_results_p1[i][\"test_score\"])\n",
    "    \n",
    "    cv_means_p2[i] = np.mean(cv_results_p2[i][\"test_score\"])\n",
    "    cv_stds_p2[i] = np.std(cv_results_p2[i][\"test_score\"])\n",
    "    \n",
    "k_p1 = k_values[np.argmax(cv_means_p1)]\n",
    "k_p2 = k_values[np.argmax(cv_means_p2)]\n",
    "\n",
    "print(k_p1)\n",
    "print(k_p2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e1476f-cbb6-4908-b4b8-510c195a61bc",
   "metadata": {},
   "source": [
    "Here in this part, I used 10-fold cross-validation to find the best k value to use in the nearest neighbor classifier. Before that, I concetenated three axes such that I provided vectors of lenght 3T to the classifiers. I chose 2 different distance measures from the Minkowski family, with p = 1(Manhattan distance) and with p = 2(Euclidean distance). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5dfab7b-f2ca-4e49-97e7-3a61d54a4abd",
   "metadata": {},
   "source": [
    "### Part b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2ca42866-492c-44b1-ad09-088d2ec1179b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Timing 1st classifier, i.e. 3-nearest-neighbor classifier with manhattan distance measure\n",
    "start_p1 = timeit.default_timer()\n",
    "classifier1 = KNeighborsClassifier(n_neighbors=k_p1, p = 1)\n",
    "classifier1.fit(X, y)\n",
    "stop_p1 = timeit.default_timer()\n",
    "time_p1 = stop_p1 - start_p1\n",
    "\n",
    "#Timing 2nd classifier, i.e. 3-nearest-neighbor classifier with euler distance measure\n",
    "start_p2 = timeit.default_timer()\n",
    "classifier2 = KNeighborsClassifier(n_neighbors=k_p2, p = 2)\n",
    "classifier2.fit(X, y)\n",
    "stop_p2 = timeit.default_timer()\n",
    "time_p2 = stop_p2 - start_p2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "937f16a2-55a8-44eb-9278-1b52a100355b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for model 1 is 0.966499162479062\n",
      "\n",
      "Run time for model 1 is 0.003537389999110019\n",
      "\n",
      "Confusion Matrix:\n",
      "[[432   0   0   2   0   3   0   0]\n",
      " [  2 443   0   0   0   0   5   2]\n",
      " [  0   2 441   0   3   6   2   0]\n",
      " [  1   0   1 438   8   2   0   0]\n",
      " [  3   0   8   1 420   0   0   1]\n",
      " [ 11   0   4   8   7 418   1   0]\n",
      " [  3  23   2   0   0   0 416   3]\n",
      " [  0   1   0   3   0   0   2 454]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy for model 1 is \"+str(classifier1.score(X,y)) +\"\\n\")\n",
    "print(\"Run time for model 1 is \"+str(time_p1) +\"\\n\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y, classifier1.predict(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "02b8f017-b18d-4e55-bfea-6d87cd985a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for model 2 is 0.9637074260189838\n",
      "\n",
      "Run time for model 2 is 0.0028684499993687496\n",
      "\n",
      "Confusion Matrix:\n",
      "[[434   0   0   2   0   1   0   0]\n",
      " [  3 442   0   0   0   0   5   2]\n",
      " [  0   2 442   0   3   5   2   0]\n",
      " [  1   0   1 436  10   2   0   0]\n",
      " [  3   0   7   0 422   0   0   1]\n",
      " [ 10   0   5   8  10 415   1   0]\n",
      " [  2  30   1   0   0   1 410   3]\n",
      " [  0   4   0   3   0   0   2 451]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy for model 2 is \"+str(classifier2.score(X,y)) +\"\\n\")\n",
    "print(\"Run time for model 2 is \"+str(time_p2) +\"\\n\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y, classifier2.predict(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8d00c3-dd77-40da-bc88-693eaeedbbff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "edb08b17-82b5-4d04-bfcf-5d42f9821aaf",
   "metadata": {},
   "source": [
    "### Part c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f433b9d8-8241-4cc0-8e16-6d9bca89990d",
   "metadata": {},
   "source": [
    "Weighting the distance based on the axes is a reasonable idea because the data consists of the coordinates of the movements in 3-d and the classes are represented in 2-d, which means that the movement in one of the axes will be useless. For example, in the cyclic motions, one axis will be the noise in the motion, probably the shaking of the accelometer while collecting the data. We can perform cross validation on the data to see if the useless axis is consistent and assign to it a very small coefficient or even zero. Also notice that this idea seems to be similar to PCA in the sense that we would reduce the dimensionality of the data if we would choose not to include an axis in the distance calculation. However, it is important to note that this suggestion assumes the noise axis is consistent in each instance so that we can remove it and not lose much information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf082b1e-f195-4817-bac4-692db437c0fc",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc26175a-6229-455e-b08b-e400010e1160",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare the concatanated distances\n",
    "data_dist_train_x = data_dist_train[:,1:,0]\n",
    "data_dist_train_y = data_dist_train[:,1:,1]\n",
    "data_dist_train_z = data_dist_train[:,1:,2]\n",
    "\n",
    "data_dist_train_concatenated = []\n",
    "\n",
    "for instance in range(896):\n",
    "    data_dist_train_concatenated.append(np.concatenate((data_dist_train_x[instance,:],\n",
    "                                           data_dist_train_y[instance,:],\n",
    "                                           data_dist_train_z[instance,:])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4a6794-bace-4ac5-8e80-ef829fd083c0",
   "metadata": {},
   "source": [
    "### Part a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20cb92ef-ff49-4a24-b908-359b200328f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = MinMaxScaler().fit_transform(data_dist_train_concatenated)\n",
    "\n",
    "y_train = data_dist_train[:,0,0] \n",
    "\n",
    "y_train_binary = (y_train == 3)*1\n",
    "\n",
    "model = LogisticRegression(random_state=0, max_iter = 100000).fit(X_train, y_train_binary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a16da58d-b77e-46b2-8cc8-fa43898b9d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2922  206]\n",
      " [  41  413]]\n",
      "0.9310441094360692\n"
     ]
    }
   ],
   "source": [
    "X_test = MinMaxScaler().fit_transform(data_dist_test_concatenated)\n",
    "\n",
    "y_test = data_dist_test[:,0,0] \n",
    "\n",
    "y_test_binary = (y_test == 3)*1\n",
    "\n",
    "probs = model.predict_proba(X_test)[:,1]\n",
    "\n",
    "class3_train_ratio = sum(y_train_binary)/len(y_train_binary)\n",
    "\n",
    "y_predicted = (probs >= class3_train_ratio)\n",
    "\n",
    "print(confusion_matrix(y_test_binary, y_predicted))\n",
    "print(accuracy_score(y_test_binary, y_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7856ed3-6e72-403b-a8f6-3dab41980c4e",
   "metadata": {},
   "source": [
    "Here above is a simple logistic regression model classifying whether one instance belongs to the class 3 or not. For decision threshold, I used the ratio of the class 3 instances in the training data. And I plotted the confusion matrix and printed the accuracy for this model. Below, I will try to improve this model by introducing penalties and different representations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9765622f-b487-4cd5-899f-dd3cea1aac56",
   "metadata": {},
   "source": [
    "### Part b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "daae75c9-73e8-41e6-9fd0-1d13963eb614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2947  181]\n",
      " [  48  406]]\n",
      "0.9360692350642099\n"
     ]
    }
   ],
   "source": [
    "C_values = np.arange(1, 30,1)\n",
    "\n",
    "cv_model_task2 = LogisticRegressionCV(cv=10,max_iter = 10000, penalty = \"l1\", scoring = \"neg_log_loss\",\n",
    "                    solver = \"liblinear\", Cs = C_values,random_state=0)\n",
    "\n",
    "cv_model_task2.fit(X_train, y_train_binary)\n",
    "\n",
    "cv_probs = cv_model_task2.predict_proba(X_test)[:,1]\n",
    "\n",
    "\n",
    "y_cv_predicted = (cv_probs >= class3_train_ratio)*1\n",
    "\n",
    "print(confusion_matrix(y_test_binary, y_cv_predicted))\n",
    "print(accuracy_score(y_test_binary, y_cv_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "95bb7a00-7e47-4984-b031-35a5bbbb5678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_model_task2.C_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "69b9eb45-4e5a-4b08-816b-4e5e577cc410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2081307988747665"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.log_loss(y_test_binary, y_cv_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2e5824-81f0-4660-bf57-1fa04f86fddb",
   "metadata": {},
   "source": [
    "Here above is a penalized version of logistic regression, with l1 penalty. The library scikitlearn has a parameter C which corresponds to the inverse of the $\\lambda$ parameter. After 10-fold cross-validation, the best C is found equal to 12 and accuracy has improved. Now, lets look at the regression coefficients and try to interpret them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3370ce44-58b1-415e-8f7a-d67dd134092c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  3.37200749e-02,  4.41214165e-02,\n",
       "         0.00000000e+00,  1.76083621e-02,  1.39460546e-01,\n",
       "         4.25251940e-03,  3.05411586e-01,  1.82488676e-01,\n",
       "         2.77740135e-01,  4.41143581e-01,  3.61889768e-01,\n",
       "         4.48415337e-01,  2.12581139e-01,  3.84607054e-01,\n",
       "         3.48090833e-01,  3.55981682e-01,  3.48381441e-01,\n",
       "         5.19600776e-01,  2.36050050e-01,  4.25374406e-01,\n",
       "         4.16598095e-01,  4.67429329e-01,  2.73408912e-01,\n",
       "         2.74481559e-01,  3.87113954e-01,  3.42768267e-01,\n",
       "         2.06269730e-01,  1.82233724e-01,  1.49455280e-01,\n",
       "         1.88191690e-01,  1.73099351e-01,  2.39494569e-01,\n",
       "         5.35096893e-03,  0.00000000e+00,  6.40477547e-02,\n",
       "         6.11480451e-03,  2.20973018e-02,  1.92831730e-01,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         1.96197808e-03,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -8.59654518e-03,\n",
       "         0.00000000e+00,  0.00000000e+00, -2.06494889e-03,\n",
       "        -1.43594702e-03, -1.40913043e-03, -2.90654379e-03,\n",
       "        -8.45373355e-02, -8.80282586e-06, -1.68874432e-01,\n",
       "        -5.22471729e-02, -2.30231490e-01, -4.41613039e-01,\n",
       "        -3.03592341e-01, -3.80681581e-01, -4.25874602e-01,\n",
       "        -2.02950361e-01, -8.05776100e-02, -1.35967025e-01,\n",
       "        -5.39732899e-01, -2.43837474e-01, -1.17758902e-01,\n",
       "        -1.57973174e-01, -3.57608677e-01, -2.30408295e-01,\n",
       "        -1.81358564e-01, -1.74363093e-02, -1.06493741e-01,\n",
       "        -3.28330044e-02, -1.48130354e-01, -2.28378633e-01,\n",
       "        -2.30166906e-02, -2.07067623e-04, -1.61626827e-03,\n",
       "        -1.11977153e-01,  0.00000000e+00,  0.00000000e+00,\n",
       "        -1.95170482e-01, -3.00759747e-02,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -2.53578071e-02,\n",
       "        -2.71626898e-01, -5.85655238e-02, -5.46034257e-01,\n",
       "        -3.28548908e-04, -1.46412814e-01, -2.19117023e-01,\n",
       "        -1.68450214e-01, -3.08470422e-01, -1.60794746e-01,\n",
       "        -1.41539400e-01, -6.86434740e-02, -2.87715415e-01,\n",
       "        -9.75647651e-02, -2.01048877e-01, -3.91800773e-01,\n",
       "        -2.34412673e-01, -1.59440198e-01, -8.00856290e-01,\n",
       "        -2.99560119e-01, -2.43753233e-01, -3.05337415e-01,\n",
       "        -3.50573474e-01, -5.69218336e-01, -2.69409354e-01,\n",
       "        -3.53522809e-01, -3.25048765e-01, -1.09551861e+00,\n",
       "        -4.44871864e-01, -4.45168234e-01, -6.28855549e-01,\n",
       "        -6.18780909e-01, -6.23454075e-01, -4.78194583e-01,\n",
       "        -4.25679451e-01, -2.95722151e-01, -5.22091145e-01,\n",
       "        -5.94729288e-01, -7.92021555e-01, -4.99707240e-01,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         3.19673743e-02,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        -1.87709035e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        -2.88512355e-02, -1.46225037e-01, -7.48691997e-02,\n",
       "        -2.32630128e-01, -3.16093680e-01, -2.68702639e-01,\n",
       "        -3.45510864e-01, -4.31818737e-01, -4.83339801e-01,\n",
       "        -5.28679017e-01, -5.51254740e-01, -4.71884502e-01,\n",
       "        -5.19136237e-01, -5.59538714e-01, -6.48719672e-01,\n",
       "        -5.29663369e-01, -6.08349278e-01, -4.76640074e-01,\n",
       "        -5.65263002e-01, -6.15743602e-01, -5.43191593e-01,\n",
       "        -6.52127872e-01, -4.80120066e-01, -5.32445968e-01,\n",
       "        -5.33497290e-01, -5.59730211e-01, -4.65886806e-01,\n",
       "        -4.09542373e-01, -4.47767167e-01, -2.68717652e-01,\n",
       "        -3.95609850e-01, -2.98188940e-01, -3.15919107e-01,\n",
       "        -3.79098537e-01, -2.91150522e-01, -2.72353009e-01,\n",
       "        -1.72422758e-01, -2.33280039e-01, -1.97996474e-01,\n",
       "        -7.05872174e-02, -2.50271334e-02, -2.32417739e-02,\n",
       "        -5.72011290e-02, -5.27350558e-02, -1.14333990e-02,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  6.39074499e-02,\n",
       "         0.00000000e+00,  0.00000000e+00,  2.66475671e-02,\n",
       "         9.80888000e-02,  1.65829306e-01,  1.01183971e-01,\n",
       "         2.24134049e-01,  7.45930324e-02,  1.32973477e-01,\n",
       "         1.05126519e-01,  1.53761951e-01,  1.73727328e-01,\n",
       "         2.14600062e-01,  2.13036584e-01,  2.94868635e-01,\n",
       "         1.74663242e-01,  2.21192070e-01,  3.81300084e-01,\n",
       "         2.08729479e-01,  2.48116762e-01,  2.35269131e-01,\n",
       "         2.98227523e-01,  2.42677949e-01,  3.69256070e-01,\n",
       "         2.90861612e-01,  3.73412007e-01,  2.19053251e-01,\n",
       "         2.36145426e-01,  3.50733797e-01,  3.46725497e-01,\n",
       "         3.10336062e-01,  3.13933732e-01,  3.44041509e-01,\n",
       "         3.68881179e-01,  3.13644413e-01,  2.94158283e-01,\n",
       "         2.19108371e-01,  3.08802151e-01,  3.36116865e-01,\n",
       "         3.05828261e-01,  2.13193911e-01,  3.18890711e-01,\n",
       "         7.30155788e-02,  3.05324920e-01,  2.78761393e-01,\n",
       "         3.14208486e-01,  2.25952009e-01,  2.71262707e-01,\n",
       "         2.96708300e-01,  3.17807887e-01,  2.54578360e-01,\n",
       "         1.89744174e-01,  3.01574669e-01,  1.94280201e-01,\n",
       "         2.41120733e-01,  1.99265251e-01,  2.47949980e-01,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        -7.74419717e-02,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        -1.02823491e-02,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -5.53880609e-02,\n",
       "         0.00000000e+00, -1.10897531e-01, -1.03252839e-01,\n",
       "        -1.34611538e-01, -1.87471759e-01, -2.20315706e-01,\n",
       "        -1.70286116e-01, -2.01268766e-01, -2.04466169e-01,\n",
       "        -2.42622092e-01, -3.86325132e-01, -3.09376286e-01,\n",
       "        -2.75213174e-01, -3.74570218e-01, -3.28034461e-01,\n",
       "        -3.49567475e-01, -4.24022946e-01, -4.22783238e-01,\n",
       "        -3.53703286e-01, -4.11195039e-01, -4.31106295e-01,\n",
       "        -3.22247080e-01, -3.72672539e-01, -2.74237958e-01,\n",
       "        -3.67419909e-01, -2.57468927e-01, -3.62241548e-01,\n",
       "        -2.98984063e-01, -2.04803474e-01, -1.63288704e-01,\n",
       "        -8.51407115e-02, -1.30897654e-01, -7.28033172e-02,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  1.33090870e-02,\n",
       "         0.00000000e+00,  0.00000000e+00,  2.52235185e-03,\n",
       "         1.84429960e-02,  7.58268775e-02,  1.68237311e-01,\n",
       "         9.40080637e-02,  1.36841280e-01,  2.05601824e-01,\n",
       "         2.01056764e-01,  8.44833398e-02,  2.29700844e-01,\n",
       "         2.98588379e-01,  3.39708436e-01,  3.89509913e-01,\n",
       "         2.71813747e-01,  2.47446260e-01,  3.95691815e-01,\n",
       "         3.87036186e-01,  3.32969506e-01,  3.88273296e-01,\n",
       "         4.04478929e-01,  3.81099770e-01,  4.26081235e-01,\n",
       "         5.60130363e-01,  4.03722609e-01,  3.71307125e-01,\n",
       "         4.08226007e-01,  4.41225066e-01,  4.10335956e-01,\n",
       "         3.63442460e-01,  3.81882205e-01,  3.74093016e-01,\n",
       "         3.22283542e-01,  4.19085703e-01,  3.86331784e-01,\n",
       "         3.89967647e-01,  3.53213645e-01,  3.25042563e-01,\n",
       "         2.30628464e-01,  3.41725200e-01,  1.96869690e-01,\n",
       "         2.21799266e-01,  2.03145317e-01,  2.21260648e-01,\n",
       "         1.27888890e-01,  1.02011654e-01,  4.82045480e-02,\n",
       "         5.51008093e-02,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -4.44204532e-02,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        -2.13854520e-02,  0.00000000e+00,  0.00000000e+00,\n",
       "        -4.27823805e-02, -7.61795986e-03, -1.32622871e-03,\n",
       "        -9.82642165e-04, -3.40997694e-03, -2.29290104e-02,\n",
       "        -9.31682038e-02, -6.54990323e-02, -1.06332990e-01,\n",
       "        -2.35119634e-02, -1.39401292e-01, -1.19015950e-01,\n",
       "        -5.73835793e-02, -9.81191319e-02, -1.85737018e-01,\n",
       "        -1.39947861e-01, -1.19244726e-01, -3.85151421e-02,\n",
       "        -1.77600266e-01, -1.92392613e-01, -1.92659915e-01,\n",
       "        -1.70017724e-01, -1.89678087e-01, -1.59791466e-01,\n",
       "        -1.77058429e-01, -2.09343672e-01, -2.77985742e-01,\n",
       "        -2.20209987e-01, -1.69937230e-01, -2.47887670e-01]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_model_task2.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3535a3e0-d5b8-4629-8403-50d97c105dca",
   "metadata": {},
   "source": [
    "Here above is the array of coefficients. Notice that for each axis, first half of the coefficients is 0, meaning the first half is not that important when classifying. This makes sense since distance is a cumulative sum of velocity and as the time progresses distance becomes more and more specific to each movement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852c117f-6f21-43bd-8cc9-f1255d1169b9",
   "metadata": {},
   "source": [
    "### Part c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "02c6b119-6bf4-4275-8ddb-43d38f8ebb4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(896, 945)\n",
      "(3582, 945)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4ba884da-96aa-4f1f-9892-b48f73a7fa36",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_train = euclidean_distances(X_train, X_train)\n",
    "dist_test = euclidean_distances(X_test, X_train)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7caa5c44-9a24-4475-9aaa-67e85d210dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3075   53]\n",
      " [  16  438]]\n",
      "0.9807370184254607\n"
     ]
    }
   ],
   "source": [
    "cv_model_task2c = LogisticRegressionCV(cv=10,max_iter = 10000, penalty = \"l1\", scoring = \"neg_log_loss\",\n",
    "                    solver = \"liblinear\", Cs = C_values,random_state=0)\n",
    "\n",
    "cv_model_task2c.fit(dist_train, y_train_binary)\n",
    "\n",
    "cv_probs_c = cv_model_task2c.predict_proba(dist_test)[:,1]\n",
    "\n",
    "\n",
    "y_cv_predicted_c = (cv_probs_c >= class3_train_ratio)*1\n",
    "\n",
    "print(confusion_matrix(y_test_binary, y_cv_predicted_c))\n",
    "print(accuracy_score(y_test_binary, y_cv_predicted_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "49558f24-0ca5-4f30-b089-1a0c862a439f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([29])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_model_task2c.C_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30b45d0-5d91-4146-9845-788d93af46b8",
   "metadata": {},
   "source": [
    "Here above is a penalized version of logistic regression applied to the distance matrices of the observations, with l1 penalty. After 10-fold cross-validation, the best C is found equal to 29 and accuracy has improved even more. This could be because now we are classifying based on how similar a test instance to the train instances. Now, lets look at the regression coefficients and try to interpret them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "87ba7648-f3ee-40ab-b3a9-4e4d3f2d5451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8.44921553e-03,  8.37183463e-03,  9.21082796e-03,\n",
       "        -7.78713335e-01, -2.19259593e-05, -9.58863553e-03,\n",
       "        -3.20219804e-02, -1.34306960e-02, -2.67427368e-02,\n",
       "         5.99056502e-04,  5.76109866e-02,  2.01561701e-02,\n",
       "        -1.35883539e-01, -3.28186177e-02, -2.30273912e-02,\n",
       "         3.00786032e-03,  8.09152126e-02, -1.01932137e-01,\n",
       "         5.49412934e-03,  8.09525218e-05,  0.00000000e+00,\n",
       "        -2.54969333e-02, -1.31485877e-02,  3.65067847e-02,\n",
       "        -1.15733222e-02,  1.60954996e-01, -2.10241304e-01,\n",
       "        -1.27733405e-02,  5.84961828e-02,  3.96635342e-01,\n",
       "         2.47257181e-02,  0.00000000e+00, -4.67333439e-03,\n",
       "         2.94763350e-03,  2.60676520e-01,  0.00000000e+00,\n",
       "        -8.22465093e-02, -2.63901129e-02, -4.53386730e-02,\n",
       "         4.62833209e-02,  1.43212543e-02,  1.14918456e-01,\n",
       "         8.56095432e-02, -1.00935085e-02,  1.45735001e-04,\n",
       "        -4.06767781e-02,  1.87231287e-02,  0.00000000e+00,\n",
       "         6.67765258e-02,  3.36330905e-02, -2.61075698e-02,\n",
       "        -7.07813435e-03,  0.00000000e+00,  1.87202058e-02,\n",
       "         0.00000000e+00,  4.43575144e-02, -3.26788212e-02,\n",
       "         1.36221435e-01, -6.92094933e-03,  1.01663681e-01,\n",
       "        -1.02492635e-01, -1.64472202e-01, -8.00097024e-05,\n",
       "         0.00000000e+00, -6.27062870e-02,  5.66227710e-02,\n",
       "         2.15928577e-01, -4.38300014e-02,  4.51733313e-02,\n",
       "         4.23836257e-02,  5.21597573e-02,  8.55104656e-03,\n",
       "         1.63116002e-01, -1.59991192e-02,  6.22135434e-02,\n",
       "         2.08187113e-01,  2.29031098e-02,  7.18375538e-02,\n",
       "         2.38032096e-02, -9.61524833e-02,  1.08314302e-01,\n",
       "        -2.75931225e-04,  3.01083364e-03,  0.00000000e+00,\n",
       "         6.44446987e-02, -3.60648801e-02,  7.59667678e-02,\n",
       "         1.46954635e-02,  3.18378465e-02,  0.00000000e+00,\n",
       "        -1.94788883e-02, -4.91163058e-02, -9.70314850e-03,\n",
       "        -1.30447771e-01,  4.38388247e-03,  3.66839217e-02,\n",
       "        -3.79824013e-01,  0.00000000e+00, -3.98158159e-01,\n",
       "         5.10515252e-02, -6.04088657e-02,  1.50542878e-02,\n",
       "         0.00000000e+00,  0.00000000e+00,  3.13043123e-03,\n",
       "        -2.38869045e-05,  6.11056966e-02,  1.06997857e-01,\n",
       "         0.00000000e+00,  3.39251331e-02,  0.00000000e+00,\n",
       "        -3.28918634e-01, -5.72229905e-04, -1.08064993e-02,\n",
       "        -7.86337546e-03, -5.62148090e-02,  3.05708465e-03,\n",
       "         3.12826290e-03,  5.32819187e-01,  2.65142232e-02,\n",
       "         1.02673897e-01,  2.07583186e-02, -9.63307137e-03,\n",
       "         3.38652334e-01, -2.38722908e-02,  2.52899933e-02,\n",
       "         6.18289904e-03,  5.18179506e-03,  1.74100081e-01,\n",
       "        -4.62878341e-02,  4.37042261e-02,  1.33425033e-02,\n",
       "        -4.82055943e-01, -1.68398044e-01,  1.93662159e-02,\n",
       "         3.57986248e-02, -2.04167370e-02,  4.76964772e-02,\n",
       "         2.67749484e-02,  0.00000000e+00,  7.20903361e-04,\n",
       "         2.04845158e-02,  0.00000000e+00,  7.91112531e-02,\n",
       "         5.39306671e-02,  2.52202119e-01, -4.58320952e-02,\n",
       "         6.11217539e-02,  4.78778830e-02, -4.46223156e-02,\n",
       "        -4.59321269e-02,  1.13401094e-03,  0.00000000e+00,\n",
       "         1.28635627e-03,  2.95681099e-02, -8.10362062e-02,\n",
       "        -1.53139375e-01, -3.56373905e-02, -6.54453786e-02,\n",
       "        -5.14677223e-02, -1.30342482e-02,  0.00000000e+00,\n",
       "        -1.46018231e-01,  0.00000000e+00,  1.47627693e-01,\n",
       "        -1.58760973e-02, -4.60061500e-01,  5.58534521e-02,\n",
       "         1.05415693e-02, -6.06182288e-03,  3.21334197e-01,\n",
       "        -5.50661406e-02,  2.91035360e-02,  2.24242061e-02,\n",
       "        -7.35530172e-05, -6.13037672e-02, -1.70305336e-05,\n",
       "         7.21458683e-02,  1.18308764e-01, -1.55701002e-02,\n",
       "         4.09271914e-02,  2.31706904e-06, -1.12591177e-01,\n",
       "         5.12118139e-03, -9.25404239e-05,  0.00000000e+00,\n",
       "         9.27597642e-02,  2.13868626e-02, -7.80671151e-01,\n",
       "         3.95040578e-02, -1.88012454e-01,  9.13345376e-02,\n",
       "         3.26662781e-02,  1.53697251e-02,  1.07453135e-02,\n",
       "         4.21170032e-04,  3.35228941e-04,  1.05770242e-02,\n",
       "         3.42123977e-01,  0.00000000e+00,  5.33597829e-03,\n",
       "         8.80805204e-05,  0.00000000e+00,  5.93360790e-03,\n",
       "         0.00000000e+00,  7.15583406e-02,  7.02030570e-05,\n",
       "        -1.47325055e-02,  4.69676110e-01, -1.33126589e-01,\n",
       "         3.11067294e-02, -2.48907687e-03,  1.03293390e-03,\n",
       "        -8.37827787e-04, -3.25230720e-01, -3.32753824e-03,\n",
       "         4.16624731e-02,  6.67336852e-02,  0.00000000e+00,\n",
       "         0.00000000e+00,  1.63261424e-01, -1.03018641e-02,\n",
       "        -7.72779342e-04,  3.14667957e-05, -1.92590270e-04,\n",
       "         6.61483115e-02,  9.80865594e-03, -5.11790381e-02,\n",
       "         4.50205368e-05, -1.33549942e-02,  0.00000000e+00,\n",
       "         7.02618892e-02, -1.29169322e-02, -4.88269088e-02,\n",
       "         1.04474479e-01,  6.00549343e-03,  3.89975801e-02,\n",
       "         8.03282496e-02, -1.50595672e-01, -7.64793269e-02,\n",
       "        -1.39691024e-04, -4.21309635e-02,  3.75554833e-02,\n",
       "        -2.29731676e-01,  0.00000000e+00,  7.41401769e-02,\n",
       "         8.67146516e-02, -3.26395498e-01, -5.41080608e-02,\n",
       "        -1.96148381e-02,  2.45764914e-02, -2.71942535e-02,\n",
       "        -1.83314903e-01, -1.29676516e-04,  4.54319072e-02,\n",
       "         8.29090213e-02,  0.00000000e+00,  7.12668353e-02,\n",
       "         2.35043707e-01,  2.48506522e-04,  0.00000000e+00,\n",
       "         2.24925952e-03,  2.39954187e-03, -2.17061578e-01,\n",
       "         3.03866450e-01,  2.15577447e-05,  4.10093892e-02,\n",
       "        -4.03781602e-02,  6.52452438e-02,  4.57922050e-02,\n",
       "         0.00000000e+00,  8.13840831e-02, -9.16904715e-03,\n",
       "         1.27488802e-02, -1.53471289e-01,  3.13452970e-02,\n",
       "        -5.93773336e-02,  0.00000000e+00,  6.25166799e-03,\n",
       "         5.42385054e-01, -3.10931958e-02,  3.33232108e-02,\n",
       "         9.28937434e-06,  6.54586618e-02, -6.12403764e-03,\n",
       "         9.79874544e-02,  0.00000000e+00,  1.03390991e-01,\n",
       "        -1.09418732e-01,  4.71810077e-02, -5.23216009e-03,\n",
       "         1.09452094e-01,  1.16941358e-01,  2.88113777e-02,\n",
       "         0.00000000e+00,  9.73251569e-03,  3.35207967e-02,\n",
       "         7.98693174e-02,  5.87094129e-03, -1.05207738e-01,\n",
       "         5.58326006e-03, -7.69852396e-02, -1.07765027e-02,\n",
       "        -4.74467490e-02,  1.36286786e-02, -4.94209692e-02,\n",
       "        -9.26281660e-02,  4.49232905e-02,  2.14329346e-02,\n",
       "        -1.12950170e-04, -5.66083326e-02,  5.97623379e-02,\n",
       "         5.13135711e-02,  3.26666591e-02,  2.18881031e-02,\n",
       "         1.29467153e-04, -4.32129979e-02,  1.35043735e-02,\n",
       "        -5.03417031e-01, -4.07063914e-01, -4.77594247e-02,\n",
       "         1.22945795e-03,  8.09780602e-03, -8.91647271e-03,\n",
       "         4.01557274e-02, -2.65150065e-02,  2.75645928e-01,\n",
       "         4.25410019e-02,  3.63903475e-02,  8.08843362e-02,\n",
       "        -3.22898724e-01,  0.00000000e+00,  1.55978231e-01,\n",
       "         2.90260485e-02,  3.00087915e-02, -5.32166032e-03,\n",
       "         3.48972068e-01,  1.53669945e-01,  8.27086554e-02,\n",
       "        -3.31436986e-02, -1.01794218e-03, -6.37929157e-03,\n",
       "         1.32778950e-02,  0.00000000e+00,  3.68759195e-04,\n",
       "         3.51776336e-05, -7.72649433e-02,  0.00000000e+00,\n",
       "         3.89883310e-02, -2.28292921e-01,  1.01994239e-02,\n",
       "        -1.24820296e-01,  1.85891458e-02, -1.56404892e-04,\n",
       "        -1.19466041e-02,  7.87041399e-02,  0.00000000e+00,\n",
       "         2.57659908e-01, -9.59516504e-02,  4.51176591e-02,\n",
       "        -6.92067532e-02, -1.53000382e-02, -1.36340989e-05,\n",
       "         0.00000000e+00,  4.46372566e-03, -6.09321078e-03,\n",
       "        -1.08824499e-01,  7.54743566e-02,  0.00000000e+00,\n",
       "         6.21775546e-02,  1.10062597e-02, -4.56284016e-02,\n",
       "         9.59504050e-02,  3.75318472e-02, -8.76443335e-04,\n",
       "        -6.87164288e-02, -4.53759744e-01,  6.16847381e-02,\n",
       "         3.49344969e-01,  5.16976787e-02,  0.00000000e+00,\n",
       "         3.90773762e-02,  1.44575843e-02,  1.57041177e-02,\n",
       "        -7.34104306e-02,  7.41045169e-03,  2.46325305e-02,\n",
       "        -2.99475628e-05, -1.46702872e-02,  0.00000000e+00,\n",
       "        -4.10153705e-01,  2.37511443e-02,  8.47257515e-02,\n",
       "        -6.86636041e-01,  7.07728152e-02,  1.18188877e-01,\n",
       "         6.04535705e-03, -6.65942296e-02, -1.34820645e-02,\n",
       "        -2.35097768e-02,  6.74887894e-04,  1.53171047e-03,\n",
       "        -3.08666670e-03,  8.13970261e-02,  1.62854413e-01,\n",
       "         7.76930972e-04,  3.03288688e-02, -1.13471073e-03,\n",
       "         3.04014180e-02,  1.44631376e-04,  4.08211164e-02,\n",
       "        -1.18270972e-01, -9.51601160e-02,  1.64441055e-02,\n",
       "         0.00000000e+00,  1.69096284e-04,  6.43811369e-02,\n",
       "         6.55171514e-02,  7.22045687e-02, -5.71534752e-02,\n",
       "        -2.28565059e-01, -3.33854815e-02, -4.65325152e-02,\n",
       "        -1.93493390e-01, -1.38474260e-01,  2.95941222e-02,\n",
       "         0.00000000e+00, -3.60665583e-02,  3.19245481e-02,\n",
       "         0.00000000e+00, -1.87312284e-01,  2.63193592e-03,\n",
       "         9.25459016e-02, -9.43488618e-02,  1.42013836e-02,\n",
       "        -2.37799229e-02, -2.64619873e-02, -3.58154163e-02,\n",
       "         0.00000000e+00,  7.10931053e-05, -2.89732114e-01,\n",
       "         3.58796946e-02,  1.01763342e-05, -2.49333436e-01,\n",
       "        -4.93100716e-03,  9.49982036e-02,  3.87860502e-02,\n",
       "        -1.69687974e-01,  3.74800869e-02, -4.02565415e-02,\n",
       "         8.02060103e-02,  7.14402722e-02,  0.00000000e+00,\n",
       "         2.50551410e-01,  6.80695440e-02, -8.18992966e-03,\n",
       "        -1.92711690e-01,  1.54241666e-01,  1.71668234e-02,\n",
       "         0.00000000e+00, -6.64940100e-02,  0.00000000e+00,\n",
       "         0.00000000e+00, -3.32765046e-01, -1.71895232e-04,\n",
       "        -3.19038435e-04,  3.32700971e-02,  0.00000000e+00,\n",
       "         0.00000000e+00,  1.58989860e-02,  6.49370665e-04,\n",
       "         1.18369023e-01, -1.91700324e-01, -2.92804442e-01,\n",
       "        -5.39386882e-02,  0.00000000e+00, -6.53986367e-02,\n",
       "        -3.71104229e-02, -1.03313570e-04,  6.10167558e-02,\n",
       "         0.00000000e+00,  5.44277827e-02,  2.08657141e-02,\n",
       "        -3.14665890e-03,  3.14673782e-01,  1.57821193e-03,\n",
       "         0.00000000e+00, -1.32079390e-01, -2.25755465e-02,\n",
       "         4.42294041e-02,  4.89953024e-02,  3.74177090e-02,\n",
       "        -2.93077534e-02,  2.11620243e-02,  7.03112867e-02,\n",
       "        -6.35413520e-02,  4.10193176e-02,  0.00000000e+00,\n",
       "        -1.20925924e-02,  1.69453063e-01,  1.69346779e-01,\n",
       "         9.30020393e-02,  7.18302497e-02,  3.43362270e-03,\n",
       "         0.00000000e+00,  1.34477983e-01, -2.46648794e-01,\n",
       "        -7.48317875e-03,  1.49840179e-02, -1.89199776e-01,\n",
       "        -3.45158566e-03,  2.55281986e-03,  1.19661751e-01,\n",
       "         0.00000000e+00, -3.71226239e-01, -3.36823327e-05,\n",
       "        -4.45838565e-02,  2.60193549e-02,  4.71393763e-03,\n",
       "        -6.35928806e-02, -5.81321068e-01, -1.40405368e-01,\n",
       "         1.57582152e-03,  1.32729987e-01,  0.00000000e+00,\n",
       "        -8.75985264e-02,  5.06511326e-02,  3.60483832e-03,\n",
       "        -1.20296626e-01, -4.76500426e-02,  1.23034194e-02,\n",
       "         0.00000000e+00,  4.91692357e-02, -7.71643484e-02,\n",
       "        -7.60895817e-02, -2.55596501e-01, -4.59848988e-03,\n",
       "         1.20970841e-01,  4.91498252e-04,  7.09032045e-02,\n",
       "         2.58533417e-02,  6.27386449e-02, -5.07310023e-02,\n",
       "         4.41412981e-01,  8.00848740e-02,  1.04407258e-02,\n",
       "        -2.45910425e-02,  1.50102260e-01, -1.05769427e-01,\n",
       "         2.42541899e-02,  6.33640052e-02,  0.00000000e+00,\n",
       "         3.72241658e-02,  1.10411672e-01,  1.16283131e-02,\n",
       "         8.21071860e-02,  0.00000000e+00, -4.09092120e-02,\n",
       "        -1.07169987e-01,  2.59508379e-03,  7.07531532e-01,\n",
       "         3.45732039e-02, -1.03809258e-01,  7.53617312e-03,\n",
       "        -8.66659425e-03,  2.34925850e-03, -5.38556459e-02,\n",
       "         0.00000000e+00, -3.57245838e-02,  1.06000184e-02,\n",
       "         4.95614739e-02, -8.29477230e-02, -5.81794054e-03,\n",
       "        -7.53606285e-05,  5.20612579e-02,  2.44931243e-02,\n",
       "         0.00000000e+00, -6.44977673e-02,  2.42165438e-02,\n",
       "        -1.75848254e-02, -2.84621316e-02, -8.57942912e-03,\n",
       "         0.00000000e+00,  3.25371322e-01,  1.35875775e-01,\n",
       "         2.82500787e-02,  2.78293188e-02,  0.00000000e+00,\n",
       "         1.11845824e+00, -3.07708406e-02,  6.49112995e-02,\n",
       "        -5.94316709e-01, -1.12545120e-01,  1.70363698e-01,\n",
       "        -4.39026839e-01,  0.00000000e+00,  3.09828930e-02,\n",
       "         4.71135833e-02,  0.00000000e+00, -4.31043197e-02,\n",
       "         0.00000000e+00,  3.55629227e-04,  0.00000000e+00,\n",
       "        -2.51473722e-02, -3.73573244e-01,  1.06946975e-01,\n",
       "         0.00000000e+00,  6.20236579e-02,  1.47195317e-01,\n",
       "        -1.19841688e-01,  3.12559558e-01, -1.74608212e-02,\n",
       "         0.00000000e+00, -7.72444214e-02, -2.84325080e-05,\n",
       "        -5.11756065e-02, -1.77146933e-03,  5.34599298e-02,\n",
       "         3.13944476e-01, -4.28278894e-02, -1.53184224e-02,\n",
       "         0.00000000e+00, -2.15827275e-02,  1.01169158e-01,\n",
       "        -4.05512586e-02,  1.33225776e-01,  4.05628178e-01,\n",
       "        -4.42269840e-02,  5.35122908e-02, -2.11508363e-01,\n",
       "         3.06372718e-02,  1.43399595e-01,  2.48474238e-02,\n",
       "        -5.39272294e-02,  8.13355261e-02,  0.00000000e+00,\n",
       "         0.00000000e+00,  5.11462611e-02,  1.46796659e-01,\n",
       "        -4.14819692e-02, -2.23826709e-02,  1.51825683e-02,\n",
       "         2.54445335e-02, -4.70458629e-05, -4.31572648e-04,\n",
       "        -5.27796160e-01,  2.85715046e-02,  5.58697894e-02,\n",
       "        -5.67200597e-02,  2.11902246e-02,  1.29448831e-02,\n",
       "         4.57116086e-02,  2.63178868e-02,  4.35244538e-04,\n",
       "         0.00000000e+00, -4.50891459e-01,  1.78476676e-02,\n",
       "        -1.00969366e-02,  4.64276304e-02,  1.39110109e-01,\n",
       "        -1.80312063e-02, -1.13314467e-01,  7.62446709e-02,\n",
       "         0.00000000e+00,  0.00000000e+00,  4.95964809e-02,\n",
       "        -2.87965130e-02,  1.12229148e-01,  1.38616460e-02,\n",
       "         3.16883107e-01, -7.24403455e-01,  1.22681545e-02,\n",
       "        -4.41011842e-02,  0.00000000e+00, -5.87310951e-02,\n",
       "         7.73272640e-02,  1.86766197e-01,  0.00000000e+00,\n",
       "         6.45319844e-02, -6.39111409e-02, -4.53133952e-02,\n",
       "         2.70504668e-02,  1.58880777e-01,  7.55207989e-03,\n",
       "        -2.92159818e-02,  2.68575771e-03, -1.18169595e-05,\n",
       "         0.00000000e+00,  1.21494234e-01,  3.09753569e-02,\n",
       "         2.91045715e-02,  0.00000000e+00,  2.91262690e-02,\n",
       "         6.80355876e-06, -2.78266407e-01,  4.93737735e-02,\n",
       "         7.28534173e-02, -7.42147187e-02,  6.32408045e-03,\n",
       "        -5.02861917e-02,  0.00000000e+00,  2.61817079e-03,\n",
       "        -6.61845234e-03, -9.01851773e-03, -4.34224166e-02,\n",
       "        -4.07184664e-03, -1.26658832e-04,  0.00000000e+00,\n",
       "        -2.15403956e-02,  2.81191165e-02, -2.89510185e-02,\n",
       "         5.18442754e-02,  4.73015157e-02, -1.10301617e-01,\n",
       "         2.34799245e-02,  9.55203498e-04,  0.00000000e+00,\n",
       "         9.04547044e-02,  7.15519849e-02, -1.00570117e-02,\n",
       "        -3.05230882e-02,  0.00000000e+00, -1.03336599e-01,\n",
       "         7.63724162e-03,  4.60673947e-02, -1.21068583e-02,\n",
       "         9.01778753e-02, -3.88833577e-02, -4.91413370e-01,\n",
       "        -1.23339577e-05, -2.09431411e-02, -7.12079380e-01,\n",
       "        -1.56313293e-02,  4.71836995e-02,  7.04982913e-02,\n",
       "        -4.47790989e-02,  0.00000000e+00,  9.07285798e-02,\n",
       "         3.45175204e-02,  3.21653232e-02,  3.42732895e-02,\n",
       "        -7.28022644e-02,  9.00666457e-02, -1.25408775e-02,\n",
       "         5.10597178e-02, -1.23580667e-01,  3.50355481e-01,\n",
       "         1.03164992e-02, -2.30257127e-02, -1.03482767e-02,\n",
       "        -1.51276527e-02,  2.67302078e-02,  1.32956469e-02,\n",
       "        -3.00318145e-02, -3.68255364e-03, -2.01614613e-02,\n",
       "         6.55647619e-03, -3.13828643e-02,  5.81877005e-02,\n",
       "         1.01689491e-02, -1.20301234e-04,  1.09655131e-01,\n",
       "         2.00606710e-01,  5.21203293e-02,  4.07443858e-02,\n",
       "        -5.06167041e-02, -5.71250259e-03, -4.33883429e-02,\n",
       "         5.68605932e-03, -3.70083867e-02, -4.02346035e-02,\n",
       "         4.85118278e-02, -1.23495708e-01,  3.86818291e-02,\n",
       "         8.00780617e-02,  0.00000000e+00, -3.25974850e-01,\n",
       "        -7.11780212e-01, -9.62772915e-03,  0.00000000e+00,\n",
       "         0.00000000e+00,  1.55907398e-02,  1.76624959e-02,\n",
       "        -5.38399341e-02,  3.39652217e-02, -4.31625394e-02,\n",
       "        -2.35076891e-01,  4.90065777e-02, -2.76035205e-01,\n",
       "        -6.04362075e-02,  1.82644833e-01,  3.22822271e-01,\n",
       "         6.96633287e-02, -4.45516791e-02, -1.58222880e-02,\n",
       "        -6.22308797e-02, -3.67923709e-02,  0.00000000e+00,\n",
       "         2.32470149e-02, -1.06162122e-02,  7.93714863e-04,\n",
       "        -1.43549716e-04,  0.00000000e+00,  6.28573156e-02,\n",
       "        -7.68182031e-02,  4.17762261e-02,  5.84492259e-02,\n",
       "        -9.24376831e-02,  3.68591028e-02,  1.81860110e-02,\n",
       "        -2.72314217e-04, -1.55891111e-02, -1.58436326e-01,\n",
       "         2.32132565e-02,  8.28689330e-05,  0.00000000e+00,\n",
       "         1.71169946e-01, -5.75484857e-02,  0.00000000e+00,\n",
       "        -2.15047557e-02,  0.00000000e+00, -1.38604011e-02,\n",
       "        -2.89903881e-02, -2.29165083e-02,  8.53147209e-01,\n",
       "         9.79355217e-03, -3.45497465e-05,  1.33342614e-01,\n",
       "        -7.50080798e-03, -1.27417131e-05,  3.43384592e-02,\n",
       "         5.16006788e-02, -4.41423037e-01,  4.63941786e-04,\n",
       "         4.65390346e-02, -3.60883914e-02, -4.85751007e-02,\n",
       "         8.29507055e-02, -3.51820948e-02,  1.32261920e-02,\n",
       "         0.00000000e+00,  6.97836358e-02, -7.89115292e-03,\n",
       "         9.58819242e-03,  1.34654626e-02,  0.00000000e+00,\n",
       "         3.10814371e-01,  0.00000000e+00,  4.44631833e-05,\n",
       "        -6.84537114e-03,  3.71783174e-03,  5.51435165e-02,\n",
       "        -2.95342621e-02,  1.24987423e-02,  8.02213179e-02,\n",
       "        -1.31271241e-01,  1.47016675e-01,  4.61309888e-02,\n",
       "         4.38516342e-02, -1.26350033e-02, -2.50194000e-02,\n",
       "         2.95034718e-02, -1.59845818e-03,  0.00000000e+00,\n",
       "        -1.78902636e-02, -1.26886666e-01, -2.51356744e-02,\n",
       "         2.89015770e-02,  0.00000000e+00,  4.35080860e-05,\n",
       "         1.09957319e-02, -2.11615435e-02,  5.15169786e-02,\n",
       "        -3.38059438e-02, -1.23062640e-01,  1.97384682e-02,\n",
       "        -4.17083872e-02,  3.06738944e-02,  0.00000000e+00,\n",
       "         0.00000000e+00,  2.72956188e-03,  9.63165732e-02,\n",
       "        -5.72569362e-01,  6.43177774e-02, -5.47355884e-03,\n",
       "         7.31709098e-02, -1.08163944e-04, -2.01129479e-01,\n",
       "         4.42869601e-03,  0.00000000e+00,  1.39280421e-01,\n",
       "        -5.09293900e-01,  1.09422158e-01,  3.47801801e-04,\n",
       "         5.14943511e-02,  4.60532393e-02]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_model_task2c.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac7871b-e779-4ff2-bedb-a9211d52dc5e",
   "metadata": {},
   "source": [
    "By looking at this array, we can say that almost every observation in the training set are important in classification based on the distance information with a few with 0 coefficients. About these 0's, we can say that they are not as important as the other observations in a sense that maybe they are outliers in terms of class-3 classification. Notice that the accuracy score has improved more. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad56c93-d949-4fea-ae41-411532038f8e",
   "metadata": {},
   "source": [
    "### Part d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175b0826-48d2-413f-a36a-0e76d1a62bc4",
   "metadata": {},
   "source": [
    "In this task, each improvement made the model better in terms of accuracy score as I have printed each one of them. Firstly, I started with a simple model. Then, I added a penalization to the model, which resulted in a better feature selection and therefore improved the test score. Lastly, I introduced another representation while keeping the penalization and it turned out that the new representation is better since the test score improved even more."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
