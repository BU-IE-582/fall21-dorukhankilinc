{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01f4ee57-3aa6-4a9f-b204-bd269c20da71",
   "metadata": {},
   "source": [
    "# IE 582 Homework 04 - Dorukhan Kılınç 2017402093\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c8f6cf6-d390-4c1d-9ef8-53bd73f0a4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040c1780-47ac-463d-9d1b-c60eb43f4267",
   "metadata": {},
   "source": [
    "## Task: Multiple Instance Learning\n",
    "\n",
    "In this task, we are asked to suggest two bag-level representations fot the given multiple instance learning problem. In this problem, the data we are given consists of bags of instances. Class labels are assigned to each bag, i.e. all the instances which are in the same bag have the same label. A bag is labeled as 0 if there are no instances labeled as 1, and 1 otherwise. \n",
    "\n",
    "In addition, we are asked to build 2 models of our choice and validata/evaluate them based on their 10 fold cv accuracy scores. Therefore, penalized logistic regression and knn classifier will be used for evaluation.\n",
    "\n",
    "### First Representation\n",
    "\n",
    "Notice that we can surely label an instance as class 0 if it belongs to a bag whose label is 0. However, we can not surely say whether instances in a bag labeled as class 1 are of class 1 or 0. Thus, the first representation takes different approaches to represent these bags. If a bag is labeled as of class 0, we simply take the average of the features as suggested in the task definition. However, this strategy would not work in the class 1 bags since even the existance of one class 1 instance results in class 1 label. Therefore, to represent these bags euclidean distance between the bag instances is taken and the instance which is the furthest to the others is selected as the representative of the bag. By doing this, we are simply selecting the most outlier instance as the representative and therefore taking into consideration the cases at which there is only one class 1 instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1565ce59-01fb-433c-8d88-f826f18c8ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Musk1.csv\", header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb9563f9-4c1b-4a84-a859-f051cb05b852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>158</th>\n",
       "      <th>159</th>\n",
       "      <th>160</th>\n",
       "      <th>161</th>\n",
       "      <th>162</th>\n",
       "      <th>163</th>\n",
       "      <th>164</th>\n",
       "      <th>165</th>\n",
       "      <th>166</th>\n",
       "      <th>167</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>-198</td>\n",
       "      <td>-109</td>\n",
       "      <td>-75</td>\n",
       "      <td>-117</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>-88</td>\n",
       "      <td>...</td>\n",
       "      <td>-238</td>\n",
       "      <td>-74</td>\n",
       "      <td>-129</td>\n",
       "      <td>-120</td>\n",
       "      <td>-38</td>\n",
       "      <td>30</td>\n",
       "      <td>48</td>\n",
       "      <td>-37</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>-191</td>\n",
       "      <td>-142</td>\n",
       "      <td>-65</td>\n",
       "      <td>-117</td>\n",
       "      <td>55</td>\n",
       "      <td>49</td>\n",
       "      <td>-170</td>\n",
       "      <td>...</td>\n",
       "      <td>-238</td>\n",
       "      <td>-302</td>\n",
       "      <td>60</td>\n",
       "      <td>-120</td>\n",
       "      <td>-39</td>\n",
       "      <td>31</td>\n",
       "      <td>48</td>\n",
       "      <td>-37</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>-191</td>\n",
       "      <td>-142</td>\n",
       "      <td>-75</td>\n",
       "      <td>-117</td>\n",
       "      <td>11</td>\n",
       "      <td>49</td>\n",
       "      <td>-161</td>\n",
       "      <td>...</td>\n",
       "      <td>-238</td>\n",
       "      <td>-73</td>\n",
       "      <td>-127</td>\n",
       "      <td>-120</td>\n",
       "      <td>-38</td>\n",
       "      <td>30</td>\n",
       "      <td>48</td>\n",
       "      <td>-37</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>-198</td>\n",
       "      <td>-110</td>\n",
       "      <td>-65</td>\n",
       "      <td>-117</td>\n",
       "      <td>55</td>\n",
       "      <td>23</td>\n",
       "      <td>-95</td>\n",
       "      <td>...</td>\n",
       "      <td>-238</td>\n",
       "      <td>-302</td>\n",
       "      <td>60</td>\n",
       "      <td>-120</td>\n",
       "      <td>-39</td>\n",
       "      <td>30</td>\n",
       "      <td>48</td>\n",
       "      <td>-37</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>-198</td>\n",
       "      <td>-102</td>\n",
       "      <td>-75</td>\n",
       "      <td>-117</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>-87</td>\n",
       "      <td>...</td>\n",
       "      <td>-238</td>\n",
       "      <td>-73</td>\n",
       "      <td>-127</td>\n",
       "      <td>51</td>\n",
       "      <td>128</td>\n",
       "      <td>144</td>\n",
       "      <td>43</td>\n",
       "      <td>-30</td>\n",
       "      <td>14</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>49</td>\n",
       "      <td>-199</td>\n",
       "      <td>-161</td>\n",
       "      <td>29</td>\n",
       "      <td>-95</td>\n",
       "      <td>-86</td>\n",
       "      <td>-48</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-220</td>\n",
       "      <td>-246</td>\n",
       "      <td>-209</td>\n",
       "      <td>33</td>\n",
       "      <td>152</td>\n",
       "      <td>134</td>\n",
       "      <td>47</td>\n",
       "      <td>-43</td>\n",
       "      <td>-15</td>\n",
       "      <td>-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>38</td>\n",
       "      <td>-123</td>\n",
       "      <td>-139</td>\n",
       "      <td>30</td>\n",
       "      <td>-117</td>\n",
       "      <td>-88</td>\n",
       "      <td>214</td>\n",
       "      <td>-13</td>\n",
       "      <td>...</td>\n",
       "      <td>-236</td>\n",
       "      <td>-226</td>\n",
       "      <td>-210</td>\n",
       "      <td>20</td>\n",
       "      <td>55</td>\n",
       "      <td>119</td>\n",
       "      <td>79</td>\n",
       "      <td>-28</td>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>43</td>\n",
       "      <td>-102</td>\n",
       "      <td>-20</td>\n",
       "      <td>-101</td>\n",
       "      <td>-116</td>\n",
       "      <td>200</td>\n",
       "      <td>-166</td>\n",
       "      <td>66</td>\n",
       "      <td>...</td>\n",
       "      <td>114</td>\n",
       "      <td>32</td>\n",
       "      <td>136</td>\n",
       "      <td>-15</td>\n",
       "      <td>143</td>\n",
       "      <td>121</td>\n",
       "      <td>55</td>\n",
       "      <td>-37</td>\n",
       "      <td>-19</td>\n",
       "      <td>-36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>39</td>\n",
       "      <td>-58</td>\n",
       "      <td>27</td>\n",
       "      <td>31</td>\n",
       "      <td>-117</td>\n",
       "      <td>-92</td>\n",
       "      <td>85</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>-228</td>\n",
       "      <td>-232</td>\n",
       "      <td>-206</td>\n",
       "      <td>13</td>\n",
       "      <td>45</td>\n",
       "      <td>116</td>\n",
       "      <td>79</td>\n",
       "      <td>-28</td>\n",
       "      <td>3</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>52</td>\n",
       "      <td>-121</td>\n",
       "      <td>-24</td>\n",
       "      <td>-104</td>\n",
       "      <td>-116</td>\n",
       "      <td>195</td>\n",
       "      <td>-162</td>\n",
       "      <td>76</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>34</td>\n",
       "      <td>133</td>\n",
       "      <td>-20</td>\n",
       "      <td>-46</td>\n",
       "      <td>95</td>\n",
       "      <td>98</td>\n",
       "      <td>-14</td>\n",
       "      <td>12</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>476 rows × 168 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9    ...  158  159  160  \\\n",
       "0      1    1   42 -198 -109  -75 -117   11   23  -88  ... -238  -74 -129   \n",
       "1      1    1   42 -191 -142  -65 -117   55   49 -170  ... -238 -302   60   \n",
       "2      1    1   42 -191 -142  -75 -117   11   49 -161  ... -238  -73 -127   \n",
       "3      1    1   42 -198 -110  -65 -117   55   23  -95  ... -238 -302   60   \n",
       "4      1    2   42 -198 -102  -75 -117   10   24  -87  ... -238  -73 -127   \n",
       "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "471    0   92   49 -199 -161   29  -95  -86  -48    2  ... -220 -246 -209   \n",
       "472    0   92   38 -123 -139   30 -117  -88  214  -13  ... -236 -226 -210   \n",
       "473    0   92   43 -102  -20 -101 -116  200 -166   66  ...  114   32  136   \n",
       "474    0   92   39  -58   27   31 -117  -92   85   21  ... -228 -232 -206   \n",
       "475    0   92   52 -121  -24 -104 -116  195 -162   76  ...   99   34  133   \n",
       "\n",
       "     161  162  163  164  165  166  167  \n",
       "0   -120  -38   30   48  -37    6   30  \n",
       "1   -120  -39   31   48  -37    5   30  \n",
       "2   -120  -38   30   48  -37    5   31  \n",
       "3   -120  -39   30   48  -37    6   30  \n",
       "4     51  128  144   43  -30   14   26  \n",
       "..   ...  ...  ...  ...  ...  ...  ...  \n",
       "471   33  152  134   47  -43  -15  -10  \n",
       "472   20   55  119   79  -28    4   74  \n",
       "473  -15  143  121   55  -37  -19  -36  \n",
       "474   13   45  116   79  -28    3   74  \n",
       "475  -20  -46   95   98  -14   12   96  \n",
       "\n",
       "[476 rows x 168 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23924878-b392-44f9-b474-4941636116dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Bag</th>\n",
       "      <th>Feature1</th>\n",
       "      <th>Feature2</th>\n",
       "      <th>Feature3</th>\n",
       "      <th>Feature4</th>\n",
       "      <th>Feature5</th>\n",
       "      <th>Feature6</th>\n",
       "      <th>Feature7</th>\n",
       "      <th>Feature8</th>\n",
       "      <th>...</th>\n",
       "      <th>Feature157</th>\n",
       "      <th>Feature158</th>\n",
       "      <th>Feature159</th>\n",
       "      <th>Feature160</th>\n",
       "      <th>Feature161</th>\n",
       "      <th>Feature162</th>\n",
       "      <th>Feature163</th>\n",
       "      <th>Feature164</th>\n",
       "      <th>Feature165</th>\n",
       "      <th>Feature166</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>-198</td>\n",
       "      <td>-109</td>\n",
       "      <td>-75</td>\n",
       "      <td>-117</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>-88</td>\n",
       "      <td>...</td>\n",
       "      <td>-238</td>\n",
       "      <td>-74</td>\n",
       "      <td>-129</td>\n",
       "      <td>-120</td>\n",
       "      <td>-38</td>\n",
       "      <td>30</td>\n",
       "      <td>48</td>\n",
       "      <td>-37</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>-191</td>\n",
       "      <td>-142</td>\n",
       "      <td>-65</td>\n",
       "      <td>-117</td>\n",
       "      <td>55</td>\n",
       "      <td>49</td>\n",
       "      <td>-170</td>\n",
       "      <td>...</td>\n",
       "      <td>-238</td>\n",
       "      <td>-302</td>\n",
       "      <td>60</td>\n",
       "      <td>-120</td>\n",
       "      <td>-39</td>\n",
       "      <td>31</td>\n",
       "      <td>48</td>\n",
       "      <td>-37</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>-191</td>\n",
       "      <td>-142</td>\n",
       "      <td>-75</td>\n",
       "      <td>-117</td>\n",
       "      <td>11</td>\n",
       "      <td>49</td>\n",
       "      <td>-161</td>\n",
       "      <td>...</td>\n",
       "      <td>-238</td>\n",
       "      <td>-73</td>\n",
       "      <td>-127</td>\n",
       "      <td>-120</td>\n",
       "      <td>-38</td>\n",
       "      <td>30</td>\n",
       "      <td>48</td>\n",
       "      <td>-37</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>-198</td>\n",
       "      <td>-110</td>\n",
       "      <td>-65</td>\n",
       "      <td>-117</td>\n",
       "      <td>55</td>\n",
       "      <td>23</td>\n",
       "      <td>-95</td>\n",
       "      <td>...</td>\n",
       "      <td>-238</td>\n",
       "      <td>-302</td>\n",
       "      <td>60</td>\n",
       "      <td>-120</td>\n",
       "      <td>-39</td>\n",
       "      <td>30</td>\n",
       "      <td>48</td>\n",
       "      <td>-37</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>-198</td>\n",
       "      <td>-102</td>\n",
       "      <td>-75</td>\n",
       "      <td>-117</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>-87</td>\n",
       "      <td>...</td>\n",
       "      <td>-238</td>\n",
       "      <td>-73</td>\n",
       "      <td>-127</td>\n",
       "      <td>51</td>\n",
       "      <td>128</td>\n",
       "      <td>144</td>\n",
       "      <td>43</td>\n",
       "      <td>-30</td>\n",
       "      <td>14</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>49</td>\n",
       "      <td>-199</td>\n",
       "      <td>-161</td>\n",
       "      <td>29</td>\n",
       "      <td>-95</td>\n",
       "      <td>-86</td>\n",
       "      <td>-48</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-220</td>\n",
       "      <td>-246</td>\n",
       "      <td>-209</td>\n",
       "      <td>33</td>\n",
       "      <td>152</td>\n",
       "      <td>134</td>\n",
       "      <td>47</td>\n",
       "      <td>-43</td>\n",
       "      <td>-15</td>\n",
       "      <td>-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>38</td>\n",
       "      <td>-123</td>\n",
       "      <td>-139</td>\n",
       "      <td>30</td>\n",
       "      <td>-117</td>\n",
       "      <td>-88</td>\n",
       "      <td>214</td>\n",
       "      <td>-13</td>\n",
       "      <td>...</td>\n",
       "      <td>-236</td>\n",
       "      <td>-226</td>\n",
       "      <td>-210</td>\n",
       "      <td>20</td>\n",
       "      <td>55</td>\n",
       "      <td>119</td>\n",
       "      <td>79</td>\n",
       "      <td>-28</td>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>43</td>\n",
       "      <td>-102</td>\n",
       "      <td>-20</td>\n",
       "      <td>-101</td>\n",
       "      <td>-116</td>\n",
       "      <td>200</td>\n",
       "      <td>-166</td>\n",
       "      <td>66</td>\n",
       "      <td>...</td>\n",
       "      <td>114</td>\n",
       "      <td>32</td>\n",
       "      <td>136</td>\n",
       "      <td>-15</td>\n",
       "      <td>143</td>\n",
       "      <td>121</td>\n",
       "      <td>55</td>\n",
       "      <td>-37</td>\n",
       "      <td>-19</td>\n",
       "      <td>-36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>39</td>\n",
       "      <td>-58</td>\n",
       "      <td>27</td>\n",
       "      <td>31</td>\n",
       "      <td>-117</td>\n",
       "      <td>-92</td>\n",
       "      <td>85</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>-228</td>\n",
       "      <td>-232</td>\n",
       "      <td>-206</td>\n",
       "      <td>13</td>\n",
       "      <td>45</td>\n",
       "      <td>116</td>\n",
       "      <td>79</td>\n",
       "      <td>-28</td>\n",
       "      <td>3</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>52</td>\n",
       "      <td>-121</td>\n",
       "      <td>-24</td>\n",
       "      <td>-104</td>\n",
       "      <td>-116</td>\n",
       "      <td>195</td>\n",
       "      <td>-162</td>\n",
       "      <td>76</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>34</td>\n",
       "      <td>133</td>\n",
       "      <td>-20</td>\n",
       "      <td>-46</td>\n",
       "      <td>95</td>\n",
       "      <td>98</td>\n",
       "      <td>-14</td>\n",
       "      <td>12</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>476 rows × 168 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Class  Bag  Feature1  Feature2  Feature3  Feature4  Feature5  Feature6  \\\n",
       "0        1    1        42      -198      -109       -75      -117        11   \n",
       "1        1    1        42      -191      -142       -65      -117        55   \n",
       "2        1    1        42      -191      -142       -75      -117        11   \n",
       "3        1    1        42      -198      -110       -65      -117        55   \n",
       "4        1    2        42      -198      -102       -75      -117        10   \n",
       "..     ...  ...       ...       ...       ...       ...       ...       ...   \n",
       "471      0   92        49      -199      -161        29       -95       -86   \n",
       "472      0   92        38      -123      -139        30      -117       -88   \n",
       "473      0   92        43      -102       -20      -101      -116       200   \n",
       "474      0   92        39       -58        27        31      -117       -92   \n",
       "475      0   92        52      -121       -24      -104      -116       195   \n",
       "\n",
       "     Feature7  Feature8  ...  Feature157  Feature158  Feature159  Feature160  \\\n",
       "0          23       -88  ...        -238         -74        -129        -120   \n",
       "1          49      -170  ...        -238        -302          60        -120   \n",
       "2          49      -161  ...        -238         -73        -127        -120   \n",
       "3          23       -95  ...        -238        -302          60        -120   \n",
       "4          24       -87  ...        -238         -73        -127          51   \n",
       "..        ...       ...  ...         ...         ...         ...         ...   \n",
       "471       -48         2  ...        -220        -246        -209          33   \n",
       "472       214       -13  ...        -236        -226        -210          20   \n",
       "473      -166        66  ...         114          32         136         -15   \n",
       "474        85        21  ...        -228        -232        -206          13   \n",
       "475      -162        76  ...          99          34         133         -20   \n",
       "\n",
       "     Feature161  Feature162  Feature163  Feature164  Feature165  Feature166  \n",
       "0           -38          30          48         -37           6          30  \n",
       "1           -39          31          48         -37           5          30  \n",
       "2           -38          30          48         -37           5          31  \n",
       "3           -39          30          48         -37           6          30  \n",
       "4           128         144          43         -30          14          26  \n",
       "..          ...         ...         ...         ...         ...         ...  \n",
       "471         152         134          47         -43         -15         -10  \n",
       "472          55         119          79         -28           4          74  \n",
       "473         143         121          55         -37         -19         -36  \n",
       "474          45         116          79         -28           3          74  \n",
       "475         -46          95          98         -14          12          96  \n",
       "\n",
       "[476 rows x 168 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = {0:\"Class\", 1:\"Bag\"}\n",
    "for i in range(166):\n",
    "    columns[i+2] = \"Feature\"+str(i+1)\n",
    "    \n",
    "data.rename(columns = columns, inplace = True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d85cc7e-99d7-46ff-bb33-bdd3c15baeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def representation1(bag):\n",
    "    bag_array = np.array(bag)\n",
    "    class_id = bag_array[0,0]\n",
    "    bag_id = bag_array[0,1]\n",
    "    features = np.array(bag.drop(columns = [\"Class\", \"Bag\"]))\n",
    "    if class_id == 0:\n",
    "        avg_features = np.average(features.T, axis = 1)\n",
    "        return np.concatenate((np.array([class_id,bag_id]), avg_features))\n",
    "    else: \n",
    "        dists = euclidean_distances(features)\n",
    "        total_distances = dists.sum(axis = 1)\n",
    "        return bag_array[np.argmax(total_distances),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c4dcc9d-f9e2-41aa-9ab6-041c19d9118f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rep1 = np.zeros((92,168))\n",
    "for bag_id in range(1,93):\n",
    "    bag = data[data[\"Bag\"]==bag_id]\n",
    "    rep1[bag_id - 1,:] = representation1(bag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2c44ab-8e59-477c-8bc7-87d9801aa3c7",
   "metadata": {},
   "source": [
    "#### Penalized Logistic Regression Applied to the First Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7cfdd8d1-04f6-4308-907a-d28dbf56af17",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = rep1[:,2:]\n",
    "y1 = rep1[:,0]\n",
    "model1 = LogisticRegressionCV(cv=10, random_state=0,\n",
    "                              max_iter = 1000).fit(X1, y1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2307d4bf-24f8-47df-bce3-141bfa0df36f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Penalization terms:\n",
      "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n",
      " 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n",
      " 1.29154967e+03 1.00000000e+04]\n",
      "\n",
      "Corresponding average cross-validation scores:\n",
      "[0.80666667 0.84666667 0.83555556 0.83555556 0.82555556 0.81444444\n",
      " 0.80444444 0.80444444 0.80444444 0.80444444]\n",
      "\n",
      "Best penalization term\n",
      "[0.00077426]\n"
     ]
    }
   ],
   "source": [
    "print(\"Penalization terms:\")\n",
    "print(model1.Cs_)\n",
    "print()\n",
    "print(\"Corresponding average cross-validation scores:\")\n",
    "print(np.average(model1.scores_[1].T,axis = 1))\n",
    "print()\n",
    "print(\"Best penalization term\")\n",
    "print(model1.C_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ff2362-5b81-44c0-9c3e-dc5baead2370",
   "metadata": {},
   "source": [
    "Here above is the cross-validation scores for penalized logistic regression and most suitable penalty term. 0.84666667 is the corresponding cv score. \n",
    "\n",
    "#### KNN Classifier Applied to the First Representation\n",
    "\n",
    "For this model, there are two parameters to tune, number of neighbors to consider when classifying (k) and the parameter of the minkowski distance. For k values I have chosen odd number up to 9 and for p values I have chosen 1 and 2 (Manhattan and Euclidean distance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0753c7e5-5bf2-4c38-9acf-1ec78e965125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0.9233333333333335, 0.8911111111111112],\n",
       " [0.9344444444444445, 0.8577777777777778],\n",
       " [0.8933333333333333, 0.8799999999999999],\n",
       " [0.8711111111111111, 0.8699999999999999],\n",
       " [0.8488888888888889, 0.8711111111111111]]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cross validation function for parameter tuning\n",
    "def cv(model, X, y):\n",
    "    \n",
    "    rskf = RepeatedStratifiedKFold(n_splits=10, n_repeats=1, random_state=0)\n",
    "    scores = []\n",
    "    \n",
    "    \n",
    "    for train_index, test_index in rskf.split(X, y):\n",
    "    \n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        \n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        scores.append(accuracy_score(y_test, model.predict(X_test)))\n",
    "    \n",
    "    return np.mean(scores)\n",
    "\n",
    "k_vals = [1, 3, 5, 7, 9]\n",
    "p_vals = [1,2]\n",
    "scores = []\n",
    "\n",
    "for k in k_vals:\n",
    "    score = []\n",
    "\n",
    "    for p in p_vals:\n",
    "        model = KNeighborsClassifier(n_neighbors = k, p = p)\n",
    "        score.append(cv(model, X1, y1))\n",
    "    \n",
    "    scores.append(score)\n",
    "\n",
    "print(\"Cross-validation scores:\")\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0925a4f8-e7cc-45ad-afa0-85b36793645c",
   "metadata": {},
   "source": [
    "Here above is the cross validation scores for k and p values. The best score is 0.9344444444444445 which corresponds to k = 3 and p = 1. Knn classifier did better than the penalized logistic regression in terms of cv score.\n",
    "\n",
    "### Second Representation\n",
    "\n",
    "This representation also takes advantage of the fact that we can surely know the labels of the instances whose bags are labeled as 0. However, instead of doing in-bag distance calculations, this time each bag is represented with the instance which is the furthest to the known zeros of the whole set. By known zeros, we mean all instances belonging to the bags with label 0. By doing this, we represent each bag with the instance which is the least similar one to the zeros and therefore check the existance of a class 1 instance in each bag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "68e7a22b-f84d-4938-b92b-f6010372593f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def representation2(bag):\n",
    "    bag_array = np.array(bag)\n",
    "    class_id = bag_array[0,0]\n",
    "    bag_id = bag_array[0,1]\n",
    "    \n",
    "    data_zeros = data[data[\"Class\"] == 0].drop(columns = [\"Class\", \"Bag\"])\n",
    "    data_zeros = np.array(data_zeros)\n",
    "    \n",
    "    features = np.array(bag.drop(columns = [\"Class\", \"Bag\"]))\n",
    "    \n",
    "    dist_to_zeros = euclidean_distances(features,data_zeros,squared = False)\n",
    "    \n",
    "    most_distant_point = np.argmax(np.sum(dist_to_zeros, axis = 1))\n",
    "    \n",
    "    return np.concatenate((np.array([class_id,bag_id]), features[most_distant_point,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eaa78c4f-5592-4b0f-879d-519edaa9e241",
   "metadata": {},
   "outputs": [],
   "source": [
    "rep2 = np.zeros((92,168))\n",
    "for bag_id in range(1,93):\n",
    "    bag = data[data[\"Bag\"]==bag_id]\n",
    "    rep2[bag_id - 1,:] = representation2(bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2c00ddf0-fda2-41bb-9882-67b4e2667acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = rep2[:,2:]\n",
    "y2 = rep2[:,0]\n",
    "model2 = LogisticRegressionCV(cv=10, random_state=0,\n",
    "                              max_iter = 1000).fit(X2, y2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8ae15031-6492-4921-954b-9230ed02ce0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Penalization terms:\n",
      "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n",
      " 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n",
      " 1.29154967e+03 1.00000000e+04]\n",
      "\n",
      "Corresponding average cross-validation scores:\n",
      "[0.79777778 0.80777778 0.80777778 0.78555556 0.78555556 0.78555556\n",
      " 0.76444444 0.76444444 0.76444444 0.76444444]\n",
      "\n",
      "Best penalization term\n",
      "[0.00077426]\n"
     ]
    }
   ],
   "source": [
    "print(\"Penalization terms:\")\n",
    "print(model2.Cs_)\n",
    "print()\n",
    "print(\"Corresponding average cross-validation scores:\")\n",
    "print(np.average(model2.scores_[1].T,axis = 1))\n",
    "print()\n",
    "print(\"Best penalization term\")\n",
    "print(model2.C_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435d9d80-db32-487a-811e-c91f7d1483fe",
   "metadata": {},
   "source": [
    "Here above is the cross-validation scores for penalized logistic regression and most suitable penalty term. 0.80777778 is the corresponding cv score. Notice that the model performance has decreased when we changed to the second representation. This might suggest that for penalized logistic regression the first representation might be a better choice.\n",
    "\n",
    "#### KNN Classifier Applied to the Second Representation\n",
    "\n",
    "Same parameters will be tried."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "42a2b112-20b3-4029-ab17-df97f289a4ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0.7922222222222223, 0.7577777777777779],\n",
       " [0.8033333333333333, 0.7822222222222222],\n",
       " [0.7288888888888889, 0.7277777777777779],\n",
       " [0.74, 0.7066666666666667],\n",
       " [0.7277777777777779, 0.6744444444444444]]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_vals = [1, 3, 5, 7, 9]\n",
    "p_vals = [1,2]\n",
    "scores = []\n",
    "\n",
    "for k in k_vals:\n",
    "    score = []\n",
    "\n",
    "    for p in p_vals:\n",
    "        model = KNeighborsClassifier(n_neighbors = k, p = p)\n",
    "        score.append(cv(model, X2, y2))\n",
    "    \n",
    "    scores.append(score)\n",
    "    \n",
    "print(\"Cross-validation scores:\")\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244d1260-6859-458d-9859-5c1cbb57d726",
   "metadata": {},
   "source": [
    "Here above is the cross validation scores for k and p values. The best score is 0.8033333333333333 which corresponds to k = 3 and p = 1. Overall, this model seems to be the worst one above all alternatives.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "All in all, we tried two different representations to solve the multiple instance learning problem and tried two different classifiers to evaluate them. Each representation was suggested considering that the instances from class 0 bags can be used to evaluate other ones. One built was upon in-bag comparisons and other was built upon global class 0 comparisons. \n",
    "\n",
    "By looking at the cv scores, we can say that the first one seems to be a better representation. However, it has a limitation which needs to be considered. This representation fails to represent the bag corretly if class 1 instances are at majority since it will choose a class 0 instance as the representative of the class. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
